# AI 기반 사격 성과 분석 및 영점 조절 보조 시스템
AI를 활용하여 사격 표적지를 분석하고, 사격 습관 교정 피드백과 영점 조절 클리크 값을 자동으로 제공하는 지능형 시스템입니다.

본 프로젝트는 군 복무 시절의 아이디어를 바탕으로, 최신 객체 탐지 모델인 YOLOv8과 컴퓨터 비전 기술을 접목하여 개발되었습니다. 사용자는 다단계 영점 사격 결과를 사진으로 입력하고, AI는 각 단계별 탄착군을 자동으로 분석하여 실시간 피드백과 누적 데이터를 제공합니다.

## 🚀 주요 기능
1. AI 기반 탄착군 탐지: YOLOv8 모델을 사용하여 어떤 환경의 표적지에서도 탄흔을 정확하게 탐지합니다.

2. 사격 습관 자동 진단: 탐지된 탄착군의 분산 형태(수직/수평/혼합)를 분석하여 호흡 불량, 조준선 불량 등 사격 습관을 자동으로 진단합니다.

3. 지능형 클리크 조절 값 제공: 분석된 탄착군 중심을 바탕으로 영점을 맞추기 위한 최적의 클리크 조절 값을 계산하여 제시합니다.

4. 다단계 사격 분석 지원: 실제 영점 사격 절차와 동일하게 1차, 2차, 3차로 진행되는 다단계 분석을 완벽하게 지원하며, 각 단계별 새로운 탄흔만을 정확히 식별합니다.

5. 결과 데이터베이스화: 모든 분석 결과는 고유 세션 ID와 함께 서버에 자동으로 기록되어, 개인별 사격 성과 데이터를 체계적으로 관리하고 추적할 수 있습니다.

6. 자동 학습 데이터셋 생성: 현실적인 AI 모델 학습을 위해, 다양한 사격 패턴(양호, 호흡불량 등)이 적용된 가상 표적지 데이터셋을 자동으로 생성합니다.

## ⚙️ 프로젝트 아키텍처
본 시스템은 상호 유기적으로 작동하는 여러 스크립트로 구성되어 있습니다.

+---------------------------+       +-------------------+       +-----------------------+
|   데이터 생성 모듈         |------>|    YOLOv8 모델     |------>|     분석 및 전송 모듈    |
| (generate_dataset.py)     |       |   (train_yolo.py) |       | (main_analyzer.py)    |
+---------------------------+       +-------------------+       +-----------------------+
            ^                                                              |
            |                                                              |
            |                                                              v
+---------------------------+                                 +-----------------------+
|  테스트 이미지 생성 모듈    |                                 |   데이터베이스 서버     |
| (generate_test_images.py) |                                 |    (db_server.py)     |
+---------------------------+                                 +-----------------------+

데이터 생성: generate_dataset_advanced.py로 AI 학습에 필요한 다양한 패턴의 표적지 이미지와 라벨 파일을 대량 생성합니다.

모델 학습: train_yolo.py 스크립트가 생성된 데이터셋을 바탕으로 '탄흔'과 '사격 패턴'을 탐지하는 best.pt 모델을 학습시킵니다.

분석 및 전송: multi_stage_analyzer.py가 학습된 모델을 사용하여 실제 표적지 이미지를 분석하고, 그 결과를 데이터베이스 서버로 전송합니다.

데이터베이스 서버: db_server.py는 Flask 기반의 간단한 서버로, 분석 결과를 수신하여 JSON 파일 형태로 영구 저장합니다.

## 🛠️ 설치 및 환경 설정
본 프로젝트는 conda 가상환경에서 실행하는 것을 권장합니다.

Conda 가상환경 생성 및 활성화

### 'aim-coach'라는 이름의 python 3.9 버전 가상환경 생성
conda create -n aim-coach python=3.9

### 가상환경 활성화
conda activate aim-coach

필수 라이브러리 설치

### 가상환경이 활성화된 상태에서 아래 명령어 실행
pip install ultralytics opencv-python numpy Flask requests Pillow`

## 📖 사용 방법
프로젝트는 아래의 순서대로 진행됩니다.

1. (선택사항) 테스트 이미지 생성
다단계 분석 스크립트를 즉시 테스트해보고 싶을 때 사용합니다.

python generate_test_images.py

test_images 폴더 안에 stage_1.jpg, stage_2.jpg, stage_3.jpg 파일이 생성됩니다.

2. 학습 데이터셋 생성
나만의 모델을 학습시키기 위해 가상 데이터셋을 생성합니다.

### 500개의 학습용 이미지 생성
python generate_dataset_advanced.py --count 500

generated_dataset_advanced 폴더 안에 이미지와 라벨, 그리고 data.yaml 파일이 생성됩니다.

3. YOLOv8 모델 학습
생성된 데이터셋으로 AI 모델을 학습시켜 best.pt 파일을 만듭니다.

### data.yaml 파일 경로를 지정하여 학습 시작
python train_yolo.py --data generated_dataset_advanced/data.yaml --epochs 150

학습이 완료되면 runs/train/shot_detection_exp/weights/best.pt 파일이 생성됩니다.

4. 데이터베이스 서버 실행
분석 결과를 수신할 서버를 실행합니다. 이 터미널 창은 분석이 끝날 때까지 끄지 말고 유지해야 합니다.

python db_server.py

터미널에 서버가 http://127.0.0.1:5000 에서 실행 중이라는 메시지가 나타납니다.

5. 최종 분석 스크립트 실행
새로운 터미널 창을 열어, 학습된 모델과 테스트 이미지를 사용하여 최종 분석을 수행합니다.

# 가상환경 활성화
conda activate aim-coach

# 분석 스크립트 실행
python multi_stage_analyzer.py --model runs/train/shot_detection_exp/weights/best.pt --user JisungKim --images test_images/stage_1.jpg test_images/stage_2.jpg test_images/stage_3.jpg

실행 후, 터미널에는 각 차수별 분석 결과가 출력되고 서버로 데이터가 전송됩니다. 웹 브라우저에서 http://127.0.0.1:5000에 접속하면 저장된 기록을 확인할 수 있습니다.

🔮 향후 발전 계획
웹 기반 UI 개발: 사용자가 웹 페이지를 통해 직접 사진을 업로드하고, 분석 결과를 시각적인 그래프와 함께 볼 수 있는 인터페이스 개발.

실시간 객체 탐지: 웹캠을 이용한 실시간 사격 자세(견착, 호흡) 분석 기능 추가.

고도화된 데이터베이스 구축: SQLite 또는 PostgreSQL 같은 관계형 데이터베이스를 도입하여 더 체계적인 데이터 관리 및 분석 기능 구현.

모델 성능 고도화: 더 많은 실제 사격 데이터를 수집하고 라벨링하여 모델의 정확도와 강인성 향상.

📄 라이선스
본 프로젝트는 MIT License를 따릅니다.